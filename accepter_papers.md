# Accepted Papers

**Not All Lotteries Are Made Equal**
<br />Surya Kant Sahu; Sai Mitheran J; Somya Suhans Mahapatra<br />
<abstract>The Lottery Ticket Hypothesis (LTH) states that for a reasonably sized neural network, a sub-network within the same network yields no less performance than the dense counterpart when trained from the same initialization. This work investigates the relation between model size and the ease of finding these sparse sub-networks. We show through experiments that, surprisingly, under a finite budget, smaller models benefit more from Ticket Search (TS).</abstract>

[PDF](https://www.dropbox.com/s/fe0f5pfqrq6z3o3/camera_ready.pdf?dl=0) &bull;
[Poster](https://www.dropbox.com/s/zwm371y78l5dbwc/poster.pdf?dl=0) &bull;
[Presentation](https://youtu.be/11y9YWItLe8)

